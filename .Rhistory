names(post) = "comments"
post$comments = as.character(post$comments)
##Pre-processing
#convert comments into corpus
postCorpus = Corpus(VectorSource(post$comments))
writeLines(as.character(postCorpus[[2]]))
#case folding
postCorpus = tm_map(postCorpus, tolower)
#remove stop words
postCorpus = tm_map(postCorpus, removeWords, stopwords('english'))
#remove punctuation marks
postCorpus = tm_map(postCorpus, removePunctuation)
#remove num bers
postCorpus = tm_map(postCorpus, removeNumbers)
#remove unnecesary spaces
postCorpus = tm_map(postCorpus, stripWhitespace)
#convert into plain text
postCorpus = tm_map(postCorpus, PlainTextDocument)
#create corpus
postCorpus = Corpus(VectorSource(postCorpus))
#Word cloud
wordcloud(postCorpus, max.words = 200, scale=c(3, .1), colors=brewer.pal(6, "Dark2"))
#Remove the defined stop words
postCorpus_WC = postCorpus
postCorpus_WC = tm_map(postCorpus, removeWords, c('i','its','it','us','also' ,'use','used','using','will','yes','say','can','take','one',
stopwords('english')))
wordcloud(postCorpus_WC, max.words = 200, scale=c(3, .1), colors=brewer.pal(6, "Dark2"))
#Build document term matrix
tdm = TermDocumentMatrix(postCorpus)
sf= data.frame(as.matrix(tdm), stringsAsFactors=FALSE)
#Most frequent terms which appears in atleast 700 times
findFreqTerms(tdm, 100)
library(RSentiment)
post = read.csv("Post.csv", header = T)
post = data.frame(post[1:50,2])
names(post) = "comments"
post$comments = as.character(post$comments)
df = calculate_sentiment(post$comments)
n=length(unique(df$sentiment))
n
#Attached sentiments to the comments
#newdocs = cbind(post, df$sentiment)
colnames(df)[1] = "comments"
df$id=c(1:length(df$sentiment))
library("ggplot2")# to plot graphs
library("scales")#to set x and y axis limit
library("psych")###to adjust the fonts
library("gplots")###for color adjustment
ggplot(df, aes_string(x = df$sentiment, y = df$id)) +
geom_bar(stat="identity",fill= "DarkSlateBlue") + theme_bw() +
xlab("comments") + scale_y_continuous(breaks=pretty_breaks(n=10)) +
ggtitle("text analysis") +  theme(text=element_text(size=15))
View(df)
shiny::runApp('~/mypro')
runApp('~/mypro')
runApp('~/mypro')
rm(list=ls())
runApp('~/mypro')
runApp('~/mypro')
runApp('~/mypro')
runApp('~/mypro')
runApp('~/mypro')
runApp('~/mypro')
#Load comments/text
post = read.csv("churn.csv", header = T)
rm(list=ls())
setwd("C:/Users/DEEKSHA/Desktop/edwisor/PracticeData")
#Load comments/text
post = read.csv("churn.csv", header = T)
rm(list=ls())
setwd("C:/Users/DEEKSHA/Desktop/edwisor/PracticeData")
getwd()
#Load comments/text
post = read.csv("churn.csv", header = T)
#Load comments/text
post = read.csv("churn_data.csv", header = T)
runApp('~/mypro')
runApp('~/mypro')
runApp('~/mypro')
rm(list=ls())
setwd("C:/Users/DEEKSHA/Desktop/edwisor/PracticeData")
library(RSentiment)
post = read.csv("Post.csv", header = T)
post = data.frame(post[1:50,2])
names(post) = "comments"
post$comments = as.character(post$comments)
df = calculate_sentiment(post$comments)
#Attached sentiments to the comments
#newdocs = cbind(post, df$sentiment)
colnames(df)[1] = "comments"
df$id=c(1:length(df$sentiment))
library("ggplot2")# to plot graphs
library("scales")#to set x and y axis limit
library("psych")###to adjust the fonts
library("gplots")###for color adjustment
ggplot(df, aes_string(x = df$sentiment, y = df$id)) +
geom_bar(stat="identity",fill= "DarkSlateBlue") + theme_bw() +
xlab("comments") + scale_y_continuous(breaks=pretty_breaks(n=10)) +
ggtitle("text analysis") +  theme(text=element_text(size=15))
runApp('~/mypro')
runApp('~/mypro')
rm(list=ls())
setwd("C:/Users/DEEKSHA/Desktop/edwisor/PracticeData")
german = read.csv("German.csv", header=T)
str(german)
#load libraries
library("ggplot2")# to plot graphs
library("scales")#to set x and y axis limit
library("corrplot")##to plot the correlation plot
library("psych")###to adjust the fonts
library("gplots")###for color adjustment
#Univariate
#Bar plot(categorical data)
#If you want count then stat="bin"
ggplot(german, aes_string(x = german$InstallmentRatePercentage, y = german$Amount)) +
geom_bar(stat="identity",fill= "DarkSlateBlue") + theme_bw() +
xlab("Installement") + scale_y_continuous(breaks=pretty_breaks(n=10)) +
ggtitle("German Data") +  theme(text=element_text(size=15))
plot + scale_y_continuous(labels = percent)
scale_y_continuous(labels = percent)
rm(list=ls())
setwd("C:/Users/DEEKSHA/Desktop/edwisor/PracticeData")
#load libraries
library(stringr)
library(tm)
library(wordcloud)
library(slam)
#Load comments/text
post = read.csv("Post.csv", header = T)
#Select only text column
post = data.frame(post[1:1000,2])
names(post) = "comments"
post$comments = as.character(post$comments)
##Pre-processing
#convert comments into corpus
postCorpus = Corpus(VectorSource(post$comments))
writeLines(as.character(postCorpus[[2]]))
#case folding
postCorpus = tm_map(postCorpus, tolower)
#remove stop words
postCorpus = tm_map(postCorpus, removeWords, stopwords('english'))
#remove punctuation marks
postCorpus = tm_map(postCorpus, removePunctuation)
#remove num bers
postCorpus = tm_map(postCorpus, removeNumbers)
#remove unnecesary spaces
postCorpus = tm_map(postCorpus, stripWhitespace)
#convert into plain text
postCorpus = tm_map(postCorpus, PlainTextDocument)
#create corpus
postCorpus = Corpus(VectorSource(postCorpus))
#Word cloud
wordcloud(postCorpus, max.words = 200, scale=c(3, .1), colors=brewer.pal(6, "Dark2"))
#Remove the defined stop words
postCorpus_WC = postCorpus
postCorpus_WC = tm_map(postCorpus, removeWords, c('i','its','it','us','also' ,'use','used','using','will','yes','say','can','take','one',
stopwords('english')))
wordcloud(postCorpus_WC, max.words = 200, scale=c(3, .1), colors=brewer.pal(6, "Dark2"))
#Build document term matrix
tdm = TermDocumentMatrix(postCorpus)
View(tdm)
sf= data.frame(as.matrix(tdm), stringsAsFactors=FALSE)
View(sf)
#Most frequent terms which appears in atleast 700 times
findFreqTerms(tdm, 100)
class(findFreqTerms(tdm, 100))
rm(list=ls())
shiny::runApp('~/mypro/test1')
rm(list=ls())
setwd("C:/Users/DEEKSHA/Desktop/edwisor/PracticeData")
#load libraries
library(stringr)
library(tm)
library(wordcloud)
library(slam)
#library(sentiment)
#Load comments/text
post = read.csv("Post.csv", header = T)
#Select only text column
post = data.frame(post[1:1000,2])
names(post) = "comments"
post$comments = as.character(post$comments)
##Pre-processing
#convert comments into corpus
postCorpus = Corpus(VectorSource(post$comments))
writeLines(as.character(postCorpus[[2]]))
#postCorpus = tm_map(postCorpus, PlainTextDocument)
#case folding
postCorpus = tm_map(postCorpus, tolower)
#remove stop words
postCorpus = tm_map(postCorpus, removeWords, stopwords('english'))
#remove punctuation marks
postCorpus = tm_map(postCorpus, removePunctuation)
#remove num bers
postCorpus = tm_map(postCorpus, removeNumbers)
#remove unnecesary spaces
postCorpus = tm_map(postCorpus, stripWhitespace)
#convert into plain text
postCorpus = tm_map(postCorpus, PlainTextDocument)
#create corpus
postCorpus = Corpus(VectorSource(postCorpus))
#Word cloud
wordcloud(postCorpus, max.words = 200, scale=c(3, .1), colors=brewer.pal(6, "Dark2"))
#Remove the defined stop words
postCorpus_WC = postCorpus
postCorpus_WC = tm_map(postCorpus, removeWords, c('i','its','it','us','also' ,'use','used','using','will','yes','say','can','take','one',
stopwords('english')))
wordcloud(postCorpus_WC, max.words = 200, scale=c(3, .1), colors=brewer.pal(6, "Dark2"))
#Build document term matrix
tdm = TermDocumentMatrix(postCorpus)
sf= data.frame(as.matrix(tdm), stringsAsFactors=FALSE)
View(sf)
writeLines(as.character(postCorpus[[3]]))
a=writeLines(as.character(postCorpus[[3]]))
a
a=writeLines(as.character(postCorpus[[4]]))
a=writeLines(as.character(postCorpus[[8]]))
a=writeLines(as.character(postCorpus[[2]]))
a
inspect(tdm[155:160,1:5])
inspect(tdm[155:160,1:3])
writeLines(as.character(postCorpus[[2]]))
rm(list=ls())
setwd("C:/Users/DEEKSHA/Desktop/edwisor/PracticeData")
#load libraries
library(stringr)
library(tm)
library(wordcloud)
library(slam)
library(sentiment)
#Load comments/text
post = read.csv("Post.csv", header = T)
#Load defined stop words
#stop_words = read.csv("stopwords.csv", header = T)
#names(stop_words) = "StopWords"
#Delete the leading spaces
post$Post = str_trim(post$Post)
#Select only text column
post = data.frame(post[1:2000,2])
names(post) = "comments"
post$comments = as.character(post$comments)
##Pre-processing
#convert comments into corpus
postCorpus = Corpus(VectorSource(post$comments))
writeLines(as.character(postCorpus[[2]]))
#postCorpus = tm_map(postCorpus, PlainTextDocument)
#case folding
postCorpus = tm_map(postCorpus, tolower)
#remove stop words
postCorpus = tm_map(postCorpus, removeWords, stopwords('english'))
#remove punctuation marks
postCorpus = tm_map(postCorpus, removePunctuation)
#remove num bers
postCorpus = tm_map(postCorpus, removeNumbers)
#remove unnecesary spaces
postCorpus = tm_map(postCorpus, stripWhitespace)
#convert into plain text
postCorpus = tm_map(postCorpus, PlainTextDocument)
#create corpus
postCorpus = Corpus(VectorSource(postCorpus))
#Build document term matrix
tdm = TermDocumentMatrix(postCorpus)
View(tdm)
sf= as.data.frame(as.matrix(tdm))
View(sf)
#tdm_min = TermDocumentMatrix(postCorpus, control=list(weighting=weightTfIdf, minWordLength=4, minDocFreq=10))
inspect(tdm[155:160,1:5])
writeLines(as.character(postCorpus[[2]]))
rm(list=ls())
setwd("C:/Users/DEEKSHA/Desktop/edwisor/PracticeData")
#load libraries
library(stringr)
library(tm)
library(wordcloud)
library(slam)
library(sentiment)
#Load comments/text
post = read.csv("Post.csv", header = T)
#Load defined stop words
#stop_words = read.csv("stopwords.csv", header = T)
#names(stop_words) = "StopWords"
#Delete the leading spaces
post$Post = str_trim(post$Post)
#Select only text column
post = data.frame(post[1:2000,2])
names(post) = "comments"
post$comments = as.character(post$comments)
##Pre-processing
#convert comments into corpus
postCorpus = Corpus(VectorSource(post$comments))
writeLines(as.character(postCorpus[[2]]))
#postCorpus = tm_map(postCorpus, PlainTextDocument)
#case folding
postCorpus = tm_map(postCorpus, tolower)
#remove stop words
postCorpus = tm_map(postCorpus, removeWords, stopwords('english'))
#remove punctuation marks
postCorpus = tm_map(postCorpus, removePunctuation)
#remove num bers
postCorpus = tm_map(postCorpus, removeNumbers)
#remove unnecesary spaces
postCorpus = tm_map(postCorpus, stripWhitespace)
#convert into plain text
postCorpus = tm_map(postCorpus, PlainTextDocument)
#create corpus
postCorpus = Corpus(VectorSource(postCorpus))
#Build document term matrix
tdm = TermDocumentMatrix(postCorpus)
#tdm_min = TermDocumentMatrix(postCorpus, control=list(weighting=weightTfIdf, minWordLength=4, minDocFreq=10))
sf= data.frame(as.matrix(tdm), stringsAsFactors=FALSE)
inspect(tdm[155:160, 1:5])
#calculate the terms frequency
words_freq = rollup(tdm, 2, na.rm=TRUE, FUN = sum)
words_freq = as.matrix(words_freq)
words_freq = data.frame(words_freq)
words_freq$words = row.names(words_freq)
row.names(words_freq) = NULL
words_freq = words_freq[,c(2,1)]
names(words_freq) = c("Words", "Frequency")
View(words_freq)
shiny::runApp('~/mypro/test1')
rm(list=ls())
setwd("G:/Analytics/Edwisor/Edwisor/Advanced Predictive Analytics/R Code/Sentiment Analysis/New folder")
#load libraries
library(stringr)
library(tm)
library(wordcloud)
library(slam)
library(sentiment)
#Load comments/text
post = read.csv("Post.csv", header = T)
#Load defined stop words
#stop_words = read.csv("stopwords.csv", header = T)
#names(stop_words) = "StopWords"
#Delete the leading spaces
post$Post = str_trim(post$Post)
#Select only text column
post = data.frame(post[1:2000,2])
names(post) = "comments"
post$comments = as.character(post$comments)
##Pre-processing
#convert comments into corpus
postCorpus = Corpus(VectorSource(post$comments))
writeLines(as.character(postCorpus[[2]]))
#postCorpus = tm_map(postCorpus, PlainTextDocument)
#case folding
postCorpus = tm_map(postCorpus, tolower)
#remove stop words
postCorpus = tm_map(postCorpus, removeWords, stopwords('english'))
#remove punctuation marks
postCorpus = tm_map(postCorpus, removePunctuation)
#remove num bers
postCorpus = tm_map(postCorpus, removeNumbers)
#remove unnecesary spaces
postCorpus = tm_map(postCorpus, stripWhitespace)
#convert into plain text
postCorpus = tm_map(postCorpus, PlainTextDocument)
#create corpus
postCorpus = Corpus(VectorSource(postCorpus))
#Build document term matrix
tdm = TermDocumentMatrix(postCorpus)
words_freq = rollup(tdm, 2, na.rm=TRUE, FUN = sum)
words_freq = as.matrix(words_freq)
words_freq = data.frame(words_freq)
words_freq$words = row.names(words_freq)
row.names(words_freq) = NULL
words_freq = words_freq[,c(2,1)]
words_freq=words_freq[,]
names(words_freq) = c("Words", "Frequency")
words_freq=words_freq[-2,]
words_freq=words_freq[3:,]
words_freq=words_freq[-1,-2,-3,]
words_freq=words_freq[3:nrow(words_freq),]
words_freq=words_freq[3:nrow(words_freq),-1]
words_freq=words_freq[3:nrow(words_freq),]
words_freq=words_freq[3:nrow(words_freq),]
words_freq = rollup(tdm, 2, na.rm=TRUE, FUN = sum)
words_freq = as.matrix(words_freq)
words_freq = data.frame(words_freq)
words_freq$words = row.names(words_freq)
row.names(words_freq) = NULL
words_freq = words_freq[,c(2,1)]
words_freq=words_freq[3:nrow(words_freq),]
words_freq=words_freq[4:nrow(words_freq),]
words_freq=words_freq[3:nrow(words_freq),]
words_freq = rollup(tdm, 2, na.rm=TRUE, FUN = sum)
words_freq = as.matrix(words_freq)
words_freq = data.frame(words_freq)
words_freq$words = row.names(words_freq)
row.names(words_freq) = NULL
words_freq = words_freq[,c(2,1)]
words_freq=words_freq[3:nrow(words_freq),]
#Most frequent terms which appears in atleast 700 times
findFreqTerms(tdm, 100)
rm(list=ls())
runApp('~/mypro/test1')
rm(list=ls())
setwd("C:/Users/DEEKSHA/Desktop/edwisor/PracticeData")
library(RSentiment)
post = read.csv("Post.csv", header = T)
post = data.frame(post[1:5,2])
names(post) = "comments"
post$comments = as.character(post$comments)
df = calculate_sentiment(post$comments)
View(df)
newdocs=df
newdocs_positive = newdocs[which(newdocs$sentiment == "Very Positive"),]
View(newdocs_positive)
shiny::runApp('~/mypro/test1')
rm(list=ls())
setwd("C:/Users/DEEKSHA/Desktop/edwisor/PracticeData")
library(RSentiment)
#load libraries
library(stringr)
library(tm)
library(wordcloud)
library(slam)
post = read.csv("Post.csv", header = T)
post = data.frame(post[1:5,2])
names(post) = "comments"
post$comments = as.character(post$comments)
df = calculate_sentiment(post$comments)
newdocs = df
#separate the comments based on polarity
newdocs_positive = newdocs[which(newdocs$sentiment == "Very Positive"),]
posCorpus = Corpus(VectorSource(newdocs_positive$sentiment))
posCorpus = tm_map(posCorpus, tolower)
posCorpus = tm_map(posCorpus, removeWords, stopwords('english'))
posCorpus = tm_map(posCorpus, removePunctuation)
posCorpus = tm_map(posCorpus, removeNumbers)
posCorpus = tm_map(posCorpus, stripWhitespace)
posCorpus = tm_map(posCorpus, PlainTextDocument)
posCorpus = Corpus(VectorSource(posCorpus))
wordcloud(posCorpus, max.words = 200, scale=c(3, .1), colors=brewer.pal(6, "Dark2"))
View(newdocs_positive)
View(newdocs_positive)
rm(list=ls())
setwd("C:/Users/DEEKSHA/Desktop/edwisor/PracticeData")
library(RSentiment)
#load libraries
library(stringr)
library(tm)
library(wordcloud)
library(slam)
post = read.csv("Post.csv", header = T)
post = data.frame(post[1:5,2])
names(post) = "comments"
post$comments = as.character(post$comments)
df = calculate_sentiment(post$comments)
newdocs = df
newdocs$sentiment = as.character(newdocs$sentiment)
#separate the comments based on polarity
newdocs_positive = newdocs[which(newdocs$sentiment == "Very Positive"),]
posCorpus = Corpus(VectorSource(newdocs_positive$sentiment))
posCorpus = tm_map(posCorpus, tolower)
posCorpus = tm_map(posCorpus, removeWords, stopwords('english'))
posCorpus = tm_map(posCorpus, removePunctuation)
posCorpus = tm_map(posCorpus, removeNumbers)
posCorpus = tm_map(posCorpus, stripWhitespace)
posCorpus = tm_map(posCorpus, PlainTextDocument)
posCorpus = Corpus(VectorSource(posCorpus))
wordcloud(posCorpus, max.words = 200, scale=c(3, .1), colors=brewer.pal(6, "Dark2"))
rm(list=ls())
setwd("C:/Users/DEEKSHA/Desktop/edwisor/PracticeData")
library(RSentiment)
#load libraries
library(stringr)
library(tm)
library(wordcloud)
library(slam)
post = read.csv("Post.csv", header = T)
post = data.frame(post[1:30,2])
names(post) = "comments"
post$comments = as.character(post$comments)
df = calculate_sentiment(post$comments)
newdocs = df
#newdocs$sentiment = as.character(newdocs$sentiment)
#separate the comments based on polarity
newdocs_positive = newdocs[which(newdocs$sentiment == "Very Positive"),]
posCorpus = Corpus(VectorSource(newdocs_positive$sentiment))
posCorpus = tm_map(posCorpus, tolower)
posCorpus = tm_map(posCorpus, removeWords, stopwords('english'))
posCorpus = tm_map(posCorpus, removePunctuation)
posCorpus = tm_map(posCorpus, removeNumbers)
posCorpus = tm_map(posCorpus, stripWhitespace)
posCorpus = tm_map(posCorpus, PlainTextDocument)
posCorpus = Corpus(VectorSource(posCorpus))
wordcloud(posCorpus, max.words = 200, scale=c(3, .1), colors=brewer.pal(6, "Dark2"))
rm(list=ls())
runApp('~/mypro/test1')
shiny::runApp('~/mypro/test1')
runApp('~/mypro/test1')
shiny::runApp()
shiny::runApp()
runApp()
shiny::runApp()
runApp()
runApp()
rm(list=ls())
runApp()
shiny::runApp()
runApp()
rm(list=ls())
shiny::runApp()
runApp()
runApp()
runApp()
shiny::runApp()
shiny::runApp()
runApp()
runApp()
shiny::runApp()
